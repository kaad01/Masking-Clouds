{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4741,"status":"ok","timestamp":1696830860022,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"},"user_tz":-120},"id":"G5nN0nGLjuPW","outputId":"99edd935-19e3-48a2-f03f-5b6ddfe8586d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12011,"status":"ok","timestamp":1696830872027,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"},"user_tz":-120},"id":"EF2lcP7sIT_A","outputId":"ad7a811d-6c93-47bf-fdcf-34144f55827b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.2)\n","Requirement already satisfied: segmentation_models_pytorch in /usr/local/lib/python3.10/dist-packages (0.3.3)\n","Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (1.3.8)\n","Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.0)\n","Collecting transformers\n","  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.3)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.0)\n","Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.7.4)\n","Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.7.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.66.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (9.4.0)\n","Requirement already satisfied: munch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.0.0)\n","Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio) (2.4.0)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.7.22)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n","Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n","Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.23.5)\n","Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.4.7)\n","Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.9.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.5.0)\n","Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (17.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n","Installing collected packages: tokenizers, transformers\n","Successfully installed tokenizers-0.14.1 transformers-4.34.0\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","zip is already the newest version (3.0-12build2).\n","0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"]}],"source":["!pip install timm segmentation_models_pytorch rasterio torchmetrics transformers\n","!apt install -y zip"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Ky9tSk6dMLdi","executionInfo":{"status":"ok","timestamp":1696830874664,"user_tz":-120,"elapsed":2640,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import f1_score\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"0hpqX8EyrmL6","executionInfo":{"status":"ok","timestamp":1696830874664,"user_tz":-120,"elapsed":7,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["params = {\n","    'backbone': 'segformer_b1',\n","    'weights': 'noisy-student',\n","    'learning_rate': 0.001,\n","    'epochs': 30,\n","    'batch_size': 24,\n","    'num_workers': 12,\n","    'device': torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'),\n","    'div_factor':10,\n","    'final_div_factor':100,\n","    'threshhold':0.5\n","}"]},{"cell_type":"markdown","metadata":{"id":"aZOSd9GK8hmW"},"source":["## Functions"]},{"cell_type":"markdown","metadata":{"id":"9gYOUfwh_UBm"},"source":["We define a function on which we can measure the accuracy of our model."]},{"cell_type":"code","source":["def sort_paths_by_number(paths):\n","    return sorted(paths, key=lambda x: int(x.split('_')[-1].split('.tif')[0]))"],"metadata":{"id":"kUQcLb4CkTm1","executionInfo":{"status":"ok","timestamp":1696830874664,"user_tz":-120,"elapsed":6,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def calculate_f1_score(pred, true, threshold=0.5):\n","    \"\"\"\n","    Compute the F1 score, also known as balanced F-score or F-measure.\n","\n","    Parameters:\n","    - true: ground truth (correct) labels, a tensor of shape [N, H, W].\n","    - pred: predicted labels, a tensor of shape [N, 1, H, W].\n","    - threshold: the prediction threshold, defaults to 0.5.\n","\n","    Returns:\n","    - F1 score\n","    \"\"\"\n","\n","    # Flatten the tensors\n","    true = true.numpy().flatten()\n","    pred = pred.numpy().flatten()\n","\n","    # Calculate F1 score\n","    f1 = f1_score(true, pred)\n","\n","    return f1"],"metadata":{"id":"iQZW7TJTbPeg","executionInfo":{"status":"ok","timestamp":1696830874665,"user_tz":-120,"elapsed":7,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"X51uVk048hFn","executionInfo":{"status":"ok","timestamp":1696830874665,"user_tz":-120,"elapsed":7,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["def intersection_and_union(pred, true):\n","    \"\"\"\n","    Calculates intersection and union for a batch of images.\n","\n","    Args:\n","        pred (torch.Tensor): a tensor of predictions\n","        true (torc.Tensor): a tensor of labels\n","\n","    Returns:\n","        intersection (int): total intersection of pixels\n","        union (int): total union of pixels\n","    \"\"\"\n","    pred = pred.squeeze(1)\n","    valid_pixel_mask = true.ne(255)  # valid pixel mask\n","    true = true.masked_select(valid_pixel_mask)\n","    pred = pred.masked_select(valid_pixel_mask)\n","\n","    # Convert to CPU and NumPy for logical operations\n","    true = true.numpy()\n","    pred = pred.numpy()\n","\n","    # Intersection and union totals\n","    intersection = np.logical_and(true, pred)\n","    union = np.logical_or(true, pred)\n","    return intersection.sum(), union.sum()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"v7O8GacG8veW","executionInfo":{"status":"ok","timestamp":1696830874665,"user_tz":-120,"elapsed":7,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["def save_model(epoch,model,ckpt_path='./',name='segformer',val_iou=0):\n","    path = os.path.join(ckpt_path, '{}_wo_ca.pth'.format(name))\n","    torch.save(model.state_dict(), path, _use_new_zipfile_serialization=False)\n","\n","def load_model(model,ckpt_path):\n","    state = torch.load(ckpt_path)\n","    model.load_state_dict(state)\n","    return model"]},{"cell_type":"markdown","source":["## Loss Functions"],"metadata":{"id":"lTvGbjxRmWnR"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"QROFzu-rjjCX","executionInfo":{"status":"ok","timestamp":1696830874665,"user_tz":-120,"elapsed":6,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["class FocalLoss(torch.nn.modules.loss._WeightedLoss):\n","    def __init__(self, weight=None, gamma=2,reduction='mean'):\n","        super(FocalLoss, self).__init__(weight,reduction=reduction)\n","        self.gamma = gamma\n","        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n","        self.bce = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n","\n","    def forward(self, input, target):\n","        #ce_loss = F.binary_cross_entropy_with_logits(input.squeeze(1), target.long(),reduction=self.reduction,weight=self.weight)\n","        ce_loss = self.bce(input.squeeze(1), target.squeeze(1))\n","        pt = torch.exp(-ce_loss)\n","        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n","        return focal_loss"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"T1khqKU6BKfD","executionInfo":{"status":"ok","timestamp":1696830874665,"user_tz":-120,"elapsed":6,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["class XEDiceLoss(torch.nn.Module):\n","    \"\"\"\n","    Computes (0.5 * CrossEntropyLoss) + (0.5 * DiceLoss).\n","    \"\"\"\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.xe = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n","        #self.xe = FocalLoss(reduction='none')\n","\n","    def forward(self, pred, true):\n","\n","        pred = pred.squeeze(1)\n","        valid_pixel_mask = true.ne(255)  # valid pixel mask\n","\n","        # Cross-entropy loss\n","        temp_true = torch.where((true == 255), 0, true)  # cast 255 to 0 temporarily\n","        xe_loss = self.xe(pred, temp_true.float())\n","        xe_loss = xe_loss.masked_select(valid_pixel_mask).mean()\n","\n","        # Dice loss\n","\n","        pred = pred.sigmoid() #torch.softmax(pred, dim=1)[:, 1]\n","\n","        pred = pred.masked_select(valid_pixel_mask)\n","        true = true.masked_select(valid_pixel_mask)\n","\n","        dice_loss = 1 - (2.0 * torch.sum(pred * true) + 1e-7) / (torch.sum(pred + true) + 1e-7)\n","\n","        #print(xe_loss,dice_loss,(2.0 * torch.sum(pred * true) + 1e-7))\n","\n","        return (0.5 * xe_loss) + (0.5 * dice_loss)"]},{"cell_type":"markdown","metadata":{"id":"lu96DfK5FFTB"},"source":["## Data\n","We create the Dataset and Dataloader"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"103-R8XwY7Rr","executionInfo":{"status":"ok","timestamp":1696830875380,"user_tz":-120,"elapsed":721,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from sklearn.model_selection import train_test_split\n","\n","import glob\n","import pandas as pd\n","import tifffile\n","import os"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"iRXoTX3cFE8l","executionInfo":{"status":"ok","timestamp":1696830875380,"user_tz":-120,"elapsed":6,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["PATH_SRC = f'/content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/src'\n","PATH_OUTPUT = f'/content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/submit'\n","PATHS_VAL = sort_paths_by_number(glob.glob(f'/content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/evaluation_true_color/evaluation_true_color_*.tif'))\n","PATHS_VAL_MASK = sort_paths_by_number(glob.glob(f'/content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/sample/evaluation_mask_*.tif'))\n","PATHS_TRAIN = sort_paths_by_number(glob.glob(f'/content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/train_true_color/train_true_color_*.tif'))\n","PATHS_TRAIN_MASK = sort_paths_by_number(glob.glob(f'/content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/train_mask/train_mask_*.tif'))"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"qKe_sULZ9u-M","executionInfo":{"status":"ok","timestamp":1696830875380,"user_tz":-120,"elapsed":6,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["class DataTransform():\n","    def __init__(self):\n","        self.data_transform = {\n","            \"train\": A.Compose(\n","                [\n","                  A.ShiftScaleRotate(shift_limit=0.0625,rotate_limit=15,p=0.5),\n","                  A.GridDistortion(p=0.35),\n","                  A.HorizontalFlip(p=0.5),\n","                  A.VerticalFlip(p=0.5),\n","                  A.GaussianBlur(p=0.25),\n","                  # A.PadIfNeeded(min_height=1024, min_width=1024, border_mode=0),\n","                  A.Resize(512, 512, interpolation=1, p=1),\n","                  ToTensorV2()\n","                ]\n","            ),\n","            \"val\": A.Compose(\n","                [\n","                  # A.PadIfNeeded(min_height=1024, min_width=1024, border_mode=0),\n","                  A.Resize(512, 512, interpolation=1, p=1),\n","                  ToTensorV2()\n","                ]\n","            )\n","        }\n","\n","    def __call__(self, phase, img, mask):\n","      return self.data_transform[phase](image=img, mask=mask)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"jBxppnsoIs__","executionInfo":{"status":"ok","timestamp":1696830875380,"user_tz":-120,"elapsed":5,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["class CloudDataset(Dataset):\n","  def __init__(self, df, phase, transform):\n","    self.data = df\n","    self.phase = phase\n","    self.transform = transform\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def normalize_data(self, image_tiff):\n","    # Normalize the image for better visualization\n","    for i in range(3):  # Assuming the image has 3 channels\n","        image_tiff[:,:,i] = (image_tiff[:,:,i] - image_tiff[:,:,i].min()) / (image_tiff[:,:,i].max() - image_tiff[:,:,i].min())\n","\n","    return image_tiff\n","\n","  def __getitem__(self, index):\n","    row = self.data.iloc[index]\n","    true_color_PATH = row['true_color']\n","    mask_PATH = row['mask']\n","    img = tifffile.imread(true_color_PATH)\n","    img = self.normalize_data(img.astype(np.float32))\n","    mask = tifffile.imread(mask_PATH)\n","    mask = mask.astype(np.float32)\n","\n","    img_and_mask = self.transform(self.phase, img, mask)\n","    img = img_and_mask[\"image\"]\n","    mask = img_and_mask[\"mask\"]\n","\n","    return img, mask"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1696830875381,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"},"user_tz":-120},"id":"rOkgjP6B9TDV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"346ddd43-73ee-44d2-e180-97b7f76249d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                                                                        true_color                                                                                 mask\n","0  /content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/train_true_color/train_true_color_0.tif  /content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/train_mask/train_mask_0.tif\n","1  /content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/train_true_color/train_true_color_1.tif  /content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/train_mask/train_mask_1.tif\n","2  /content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/train_true_color/train_true_color_2.tif  /content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/train_mask/train_mask_2.tif\n","3  /content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/train_true_color/train_true_color_3.tif  /content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/train_mask/train_mask_3.tif\n","4  /content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/train_true_color/train_true_color_4.tif  /content/drive/MyDrive/Projekte/Solafune/Cloud_satelite/train_mask/train_mask_4.tif\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-44df3b6a699d>:8: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n","  pd.set_option('max_colwidth', -1)\n"]}],"source":["df = pd.DataFrame({\n","    'true_color': PATHS_TRAIN,\n","    'mask': PATHS_TRAIN_MASK\n","})\n","\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.expand_frame_repr', False)\n","pd.set_option('max_colwidth', -1)\n","print(df.head())\n","\n","df_train, df_val = train_test_split(df, test_size=0.2, random_state=42)\n","\n","train_dataset = CloudDataset(df_train, phase=\"train\", transform=DataTransform())\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=params['batch_size'],\n","    shuffle=True,\n","    num_workers=params['num_workers'],\n","    pin_memory=True,\n","    persistent_workers=True\n",")\n","\n","\n","val_dataset = CloudDataset(df_val, phase=\"val\", transform=DataTransform())\n","val_dataloader = DataLoader(\n","    val_dataset,\n","    batch_size=params['batch_size'],\n","    shuffle=True,\n","    num_workers=params['num_workers'],\n","    pin_memory=True,\n","    persistent_workers=True\n",")\n","\n","dataloaders_dict = {\n","    'train': train_dataloader,\n","    'val': val_dataloader\n","}"]},{"cell_type":"markdown","metadata":{"id":"dfIg3jW2ny37"},"source":["## Model\n","We implement the cloud detection Model based on the Microsoft Competion Winner: https://github.com/drivendataorg/cloud-cover-winners/blob/main/1st%20place/src/unet_efficient_net_b1_train_fp16.py"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"X1DVk84slhV_","executionInfo":{"status":"ok","timestamp":1696830876061,"user_tz":-120,"elapsed":685,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["from transformers import SegformerForSemanticSegmentation\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"3jDKCdg7qPs0","executionInfo":{"status":"ok","timestamp":1696830876061,"user_tz":-120,"elapsed":8,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","\n","        self.segformer = SegformerForSemanticSegmentation.from_pretrained('nvidia/segformer-b1-finetuned-ade-512-512')\n","        self.segformer.decode_head.classifier = nn.Conv2d(256,1,kernel_size=1)\n","    # @torch.cuda.amp.autocast()\n","    def forward(self, image):\n","        batch_size = len(image)\n","        image = image\n","        mask = self.segformer(image).logits\n","        mask = F.interpolate(mask, image.shape[-2:], mode=\"bilinear\", align_corners=True)\n","        mask = mask.squeeze(1)\n","\n","        return mask\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["bdf3be2c2ae74e4db188c73a4e7c0c8e","dd2069e0c45a4fb2b576dbe1135cc7d9","209ad6e0f28f4c838b9daa81a25d7a1e","2cb11161d9e540908fd5e8b45fc4b368","9c78be33c0764fbfbc8d88d7fa755746","2029facba8b746c297dc47c5f145de92","ddbba79759c5449da83e73f5cb14e021","fbaf1dacadd94e47b181988d58f55ebd","3555715350994afcbd96f3e7042a742c","9134b8ec80e24447a938f81affd5d7e0","c256bf3250dd49c2bb798cb35889b739","32020a57b7d54da9a9dc9e91a6d9c989","b3281f7b09f54fa381297d832955ff40","bc3c489fb0854cc3a34723be9831ed3c","7baba65c94244f0189c44122c468ddfc","5d992fa6502044bdb192cabf3ae87b29","a11be9f2935a412f81b8b3706e3ba2b0","a428bd8a53124a6db5e4ce694d4a6334","8686c6a966774035a7ebd46992e7b699","df3eba0ab6b543c5beb52b6ba28dfac1","fa8cb31b9d8a49a6875ca3796f6d5a29","5aa9bc0bc040459ea7f6d8c9173185b3"]},"executionInfo":{"elapsed":25804,"status":"ok","timestamp":1696830963567,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"},"user_tz":-120},"id":"mHmxaQetAv52","outputId":"ebfc91c5-ef97-452f-d0fa-951998b47638"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/6.88k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdf3be2c2ae74e4db188c73a4e7c0c8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/54.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32020a57b7d54da9a9dc9e91a6d9c989"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (segformer): SegformerForSemanticSegmentation(\n","    (segformer): SegformerModel(\n","      (encoder): SegformerEncoder(\n","        (patch_embeddings): ModuleList(\n","          (0): SegformerOverlapPatchEmbeddings(\n","            (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n","            (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (1): SegformerOverlapPatchEmbeddings(\n","            (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","            (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (2): SegformerOverlapPatchEmbeddings(\n","            (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","            (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (3): SegformerOverlapPatchEmbeddings(\n","            (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","            (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (block): ModuleList(\n","          (0): ModuleList(\n","            (0): SegformerLayer(\n","              (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","              (attention): SegformerAttention(\n","                (self): SegformerEfficientSelfAttention(\n","                  (query): Linear(in_features=64, out_features=64, bias=True)\n","                  (key): Linear(in_features=64, out_features=64, bias=True)\n","                  (value): Linear(in_features=64, out_features=64, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                  (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n","                  (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","                )\n","                (output): SegformerSelfOutput(\n","                  (dense): Linear(in_features=64, out_features=64, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","              (drop_path): Identity()\n","              (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","              (mlp): SegformerMixFFN(\n","                (dense1): Linear(in_features=64, out_features=256, bias=True)\n","                (dwconv): SegformerDWConv(\n","                  (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","                )\n","                (intermediate_act_fn): GELUActivation()\n","                (dense2): Linear(in_features=256, out_features=64, bias=True)\n","                (dropout): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (1): SegformerLayer(\n","              (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","              (attention): SegformerAttention(\n","                (self): SegformerEfficientSelfAttention(\n","                  (query): Linear(in_features=64, out_features=64, bias=True)\n","                  (key): Linear(in_features=64, out_features=64, bias=True)\n","                  (value): Linear(in_features=64, out_features=64, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                  (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n","                  (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","                )\n","                (output): SegformerSelfOutput(\n","                  (dense): Linear(in_features=64, out_features=64, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","              (drop_path): SegformerDropPath(p=0.014285714365541935)\n","              (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","              (mlp): SegformerMixFFN(\n","                (dense1): Linear(in_features=64, out_features=256, bias=True)\n","                (dwconv): SegformerDWConv(\n","                  (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","                )\n","                (intermediate_act_fn): GELUActivation()\n","                (dense2): Linear(in_features=256, out_features=64, bias=True)\n","                (dropout): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","          )\n","          (1): ModuleList(\n","            (0): SegformerLayer(\n","              (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","              (attention): SegformerAttention(\n","                (self): SegformerEfficientSelfAttention(\n","                  (query): Linear(in_features=128, out_features=128, bias=True)\n","                  (key): Linear(in_features=128, out_features=128, bias=True)\n","                  (value): Linear(in_features=128, out_features=128, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                  (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","                  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","                )\n","                (output): SegformerSelfOutput(\n","                  (dense): Linear(in_features=128, out_features=128, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","              (drop_path): SegformerDropPath(p=0.02857142873108387)\n","              (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","              (mlp): SegformerMixFFN(\n","                (dense1): Linear(in_features=128, out_features=512, bias=True)\n","                (dwconv): SegformerDWConv(\n","                  (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                )\n","                (intermediate_act_fn): GELUActivation()\n","                (dense2): Linear(in_features=512, out_features=128, bias=True)\n","                (dropout): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (1): SegformerLayer(\n","              (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","              (attention): SegformerAttention(\n","                (self): SegformerEfficientSelfAttention(\n","                  (query): Linear(in_features=128, out_features=128, bias=True)\n","                  (key): Linear(in_features=128, out_features=128, bias=True)\n","                  (value): Linear(in_features=128, out_features=128, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                  (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","                  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","                )\n","                (output): SegformerSelfOutput(\n","                  (dense): Linear(in_features=128, out_features=128, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","              (drop_path): SegformerDropPath(p=0.04285714402794838)\n","              (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","              (mlp): SegformerMixFFN(\n","                (dense1): Linear(in_features=128, out_features=512, bias=True)\n","                (dwconv): SegformerDWConv(\n","                  (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                )\n","                (intermediate_act_fn): GELUActivation()\n","                (dense2): Linear(in_features=512, out_features=128, bias=True)\n","                (dropout): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","          )\n","          (2): ModuleList(\n","            (0): SegformerLayer(\n","              (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n","              (attention): SegformerAttention(\n","                (self): SegformerEfficientSelfAttention(\n","                  (query): Linear(in_features=320, out_features=320, bias=True)\n","                  (key): Linear(in_features=320, out_features=320, bias=True)\n","                  (value): Linear(in_features=320, out_features=320, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                  (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","                  (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n","                )\n","                (output): SegformerSelfOutput(\n","                  (dense): Linear(in_features=320, out_features=320, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","              (drop_path): SegformerDropPath(p=0.05714285746216774)\n","              (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n","              (mlp): SegformerMixFFN(\n","                (dense1): Linear(in_features=320, out_features=1280, bias=True)\n","                (dwconv): SegformerDWConv(\n","                  (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                )\n","                (intermediate_act_fn): GELUActivation()\n","                (dense2): Linear(in_features=1280, out_features=320, bias=True)\n","                (dropout): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (1): SegformerLayer(\n","              (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n","              (attention): SegformerAttention(\n","                (self): SegformerEfficientSelfAttention(\n","                  (query): Linear(in_features=320, out_features=320, bias=True)\n","                  (key): Linear(in_features=320, out_features=320, bias=True)\n","                  (value): Linear(in_features=320, out_features=320, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                  (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","                  (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n","                )\n","                (output): SegformerSelfOutput(\n","                  (dense): Linear(in_features=320, out_features=320, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","              (drop_path): SegformerDropPath(p=0.0714285746216774)\n","              (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n","              (mlp): SegformerMixFFN(\n","                (dense1): Linear(in_features=320, out_features=1280, bias=True)\n","                (dwconv): SegformerDWConv(\n","                  (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                )\n","                (intermediate_act_fn): GELUActivation()\n","                (dense2): Linear(in_features=1280, out_features=320, bias=True)\n","                (dropout): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","          )\n","          (3): ModuleList(\n","            (0): SegformerLayer(\n","              (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attention): SegformerAttention(\n","                (self): SegformerEfficientSelfAttention(\n","                  (query): Linear(in_features=512, out_features=512, bias=True)\n","                  (key): Linear(in_features=512, out_features=512, bias=True)\n","                  (value): Linear(in_features=512, out_features=512, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","                (output): SegformerSelfOutput(\n","                  (dense): Linear(in_features=512, out_features=512, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","              (drop_path): SegformerDropPath(p=0.08571428805589676)\n","              (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): SegformerMixFFN(\n","                (dense1): Linear(in_features=512, out_features=2048, bias=True)\n","                (dwconv): SegformerDWConv(\n","                  (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n","                )\n","                (intermediate_act_fn): GELUActivation()\n","                (dense2): Linear(in_features=2048, out_features=512, bias=True)\n","                (dropout): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (1): SegformerLayer(\n","              (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (attention): SegformerAttention(\n","                (self): SegformerEfficientSelfAttention(\n","                  (query): Linear(in_features=512, out_features=512, bias=True)\n","                  (key): Linear(in_features=512, out_features=512, bias=True)\n","                  (value): Linear(in_features=512, out_features=512, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","                (output): SegformerSelfOutput(\n","                  (dense): Linear(in_features=512, out_features=512, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","              (drop_path): SegformerDropPath(p=0.10000000149011612)\n","              (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (mlp): SegformerMixFFN(\n","                (dense1): Linear(in_features=512, out_features=2048, bias=True)\n","                (dwconv): SegformerDWConv(\n","                  (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n","                )\n","                (intermediate_act_fn): GELUActivation()\n","                (dense2): Linear(in_features=2048, out_features=512, bias=True)\n","                (dropout): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","          )\n","        )\n","        (layer_norm): ModuleList(\n","          (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","          (2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n","          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (decode_head): SegformerDecodeHead(\n","      (linear_c): ModuleList(\n","        (0): SegformerMLP(\n","          (proj): Linear(in_features=64, out_features=256, bias=True)\n","        )\n","        (1): SegformerMLP(\n","          (proj): Linear(in_features=128, out_features=256, bias=True)\n","        )\n","        (2): SegformerMLP(\n","          (proj): Linear(in_features=320, out_features=256, bias=True)\n","        )\n","        (3): SegformerMLP(\n","          (proj): Linear(in_features=512, out_features=256, bias=True)\n","        )\n","      )\n","      (linear_fuse): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (activation): ReLU()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","      (classifier): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":19}],"source":["model = Net()\n","model.to(params['device'])"]},{"cell_type":"markdown","metadata":{"id":"8KNeU2FArXUm"},"source":["## Training"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"Oj2AfZr3ZQQf","executionInfo":{"status":"ok","timestamp":1696830963567,"user_tz":-120,"elapsed":2,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["from tqdm import tqdm\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1696830965984,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"},"user_tz":-120},"id":"YXi1aPmTEcS5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9176b766-3178-4fc2-f1cb-850ec93c0241"},"outputs":[{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.0000e-04.\n"]}],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])\n","\n","scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","      optimizer,\n","      steps_per_epoch = 42,\n","      pct_start = 0.1,\n","      max_lr = params['learning_rate'],\n","      epochs = params['epochs'],\n","      div_factor = params['div_factor'],\n","      final_div_factor = params['final_div_factor'],\n","      verbose = True\n","    )\n","\n","# criterion = FocalLoss()\n","criterion = XEDiceLoss()"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"0mCrJIH7rV4D","executionInfo":{"status":"ok","timestamp":1696830971319,"user_tz":-120,"elapsed":3,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["def train(model, img, mask):\n","  model.train()\n","  optimizer.zero_grad()\n","\n","  preds = model(img)\n","  loss = criterion(preds, mask)\n","  # loss = criterion(preds.squeeze(dim=1), mask.squeeze(dim=1))\n","  loss.backward()\n","  optimizer.step()\n","  loss = loss.item()\n","\n","  # Calculate validation IOU (global)\n","  preds = (preds.detach().sigmoid().cpu() > params['threshhold']) *1\n","  mask = mask.detach().cpu()\n","\n","  # plt.imshow(preds[0][0], cmap='gray')\n","  # plt.colorbar()\n","  # plt.title(\"pred\")\n","  # plt.show()\n","\n","  # plt.imshow(mask[0], cmap='gray')\n","  # plt.colorbar()\n","  # plt.title(\"mask\")\n","  # plt.show()\n","\n","\n","  intersection, union = intersection_and_union(preds, mask)\n","  f1_score = calculate_f1_score(preds, mask)\n","\n","  return loss, intersection, union, f1_score"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"ynkmnqxgCvLC","executionInfo":{"status":"ok","timestamp":1696830973239,"user_tz":-120,"elapsed":3,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["def val(model, img, mask):\n","  model.eval()\n","  with torch.no_grad():\n","    preds = model(img)\n","    loss = criterion(preds, mask)\n","    # loss = criterion(preds.squeeze(dim=1), mask.squeeze(dim=1))\n","    loss = loss.item()\n","\n","    preds = (preds.detach().sigmoid().cpu() > params['threshhold']) *1 #torch.softmax(preds, dim=1)[:, 1]\n","    mask = mask.detach().cpu()\n","    intersection, union = intersection_and_union(preds, mask)\n","    f1_score = calculate_f1_score(preds, mask)\n","\n","  return loss, intersection, union, f1_score"]},{"cell_type":"markdown","metadata":{"id":"Uu4xZwfZapP3"},"source":["Delete GPU-RAM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h0G1VzLAaoqX","executionInfo":{"status":"aborted","timestamp":1696830876062,"user_tz":-120,"elapsed":6,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[],"source":["import gc  # Garbage Collector\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cf9lZjD2DC0E","outputId":"c464135b-4638-4bc9-c51a-6555ba5b6a68","executionInfo":{"status":"ok","timestamp":1696836430342,"user_tz":-120,"elapsed":5454353,"user":{"displayName":"Kaan Dönmez","userId":"08741966824861432724"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch: 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [03:09<00:00,  5.56s/it, iou=0.501, loss=0.458, f1=0.695]"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.0014e-04.\n","    Phase: train -->  loss=0.45755885541439056 iou=0.5009078315136963 f1=0.6947050914645714\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|██████████| 9/9 [01:01<00:00,  6.84s/it, iou=0.68, loss=0.346, f1=0.8]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.34601373473803204 iou=0.6797498490780662 f1=0.8004121998997387\n","Saving model with iou 0.6797498490780662\n","\n","Epoch: 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:24<00:00,  4.25s/it, iou=0.674, loss=0.321, f1=0.794]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.0057e-04.\n","    Phase: train -->  loss=0.32073792552246766 iou=0.6742608851222415 f1=0.7938374495746389\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:36<00:00,  4.05s/it, iou=0.74, loss=0.248, f1=0.832]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.24766039186053806 iou=0.7400682177048813 f1=0.8322333171132463\n","Saving model with iou 0.7400682177048813\n","\n","Epoch: 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:27<00:00,  4.35s/it, iou=0.707, loss=0.282, f1=0.798]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.0128e-04.\n","    Phase: train -->  loss=0.2823442501180312 iou=0.7066673675684411 f1=0.7977148031320783\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:34<00:00,  3.80s/it, iou=0.744, loss=0.213, f1=0.856]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.21348668138186136 iou=0.744332652113976 f1=0.8555924792690051\n","Saving model with iou 0.744332652113976\n","\n","Epoch: 4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:24<00:00,  4.26s/it, iou=0.749, loss=0.239, f1=0.833]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.0227e-04.\n","    Phase: train -->  loss=0.2392880815793486 iou=0.7485927170567649 f1=0.8334531180383393\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.92s/it, iou=0.729, loss=0.234, f1=0.837]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.2335176004303826 iou=0.7289770555732518 f1=0.837027834202962\n","Not saving for iou 0.7289770555732518\n","\n","Epoch: 5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:23<00:00,  4.22s/it, iou=0.749, loss=0.222, f1=0.841]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.0355e-04.\n","    Phase: train -->  loss=0.22239498180501602 iou=0.7494240847419291 f1=0.8407099301608366\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.92s/it, iou=0.757, loss=0.192, f1=0.857]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.19241996109485626 iou=0.7571573967524918 f1=0.8574829260804124\n","Saving model with iou 0.7571573967524918\n","\n","Epoch: 6\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:19<00:00,  4.11s/it, iou=0.764, loss=0.192, f1=0.86]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.0511e-04.\n","    Phase: train -->  loss=0.19166073444135048 iou=0.7640321837098618 f1=0.8603445806627613\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.90s/it, iou=0.775, loss=0.176, f1=0.871]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.17634420428011152 iou=0.7754378399926966 f1=0.8708237862141773\n","Saving model with iou 0.7754378399926966\n","\n","Epoch: 7\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:22<00:00,  4.20s/it, iou=0.768, loss=0.179, f1=0.864]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.0695e-04.\n","    Phase: train -->  loss=0.17899461243959033 iou=0.7680900299934327 f1=0.8635772189292701\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.90s/it, iou=0.759, loss=0.173, f1=0.866]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.1726595030890571 iou=0.7589442829621782 f1=0.8660063156557899\n","Not saving for iou 0.7589442829621782\n","\n","Epoch: 8\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:23<00:00,  4.23s/it, iou=0.761, loss=0.182, f1=0.853]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.0907e-04.\n","    Phase: train -->  loss=0.18199973882121198 iou=0.7609175537656278 f1=0.8534146077340862\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.96s/it, iou=0.745, loss=0.201, f1=0.843]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.20104240046607125 iou=0.7449527975995631 f1=0.8434754973889113\n","Not saving for iou 0.7449527975995631\n","\n","Epoch: 9\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:24<00:00,  4.25s/it, iou=0.779, loss=0.165, f1=0.87]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.1146e-04.\n","    Phase: train -->  loss=0.16512719870490186 iou=0.7793941071047743 f1=0.870424714776242\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.93s/it, iou=0.731, loss=0.193, f1=0.841]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.1929986369278696 iou=0.7314269535447395 f1=0.8411950252867627\n","Not saving for iou 0.7314269535447395\n","\n","Epoch: 10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:23<00:00,  4.22s/it, iou=0.767, loss=0.167, f1=0.861]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.1414e-04.\n","    Phase: train -->  loss=0.16668965733226607 iou=0.7673866975429047 f1=0.8607081817076746\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.90s/it, iou=0.763, loss=0.179, f1=0.848]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.17904886272218493 iou=0.7632057462388872 f1=0.8480309150371755\n","Not saving for iou 0.7632057462388872\n","\n","Epoch: 11\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:24<00:00,  4.26s/it, iou=0.809, loss=0.142, f1=0.89]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.1709e-04.\n","    Phase: train -->  loss=0.14183620867483757 iou=0.8088455461399984 f1=0.8897163435653253\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:33<00:00,  3.73s/it, iou=0.78, loss=0.164, f1=0.862]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.16379652751816642 iou=0.7798297467017564 f1=0.8623790918054763\n","Saving model with iou 0.7798297467017564\n","\n","Epoch: 12\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:23<00:00,  4.21s/it, iou=0.814, loss=0.133, f1=0.892]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.2031e-04.\n","    Phase: train -->  loss=0.13281912619576736 iou=0.8141846562499527 f1=0.8918139991769303\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:33<00:00,  3.73s/it, iou=0.792, loss=0.148, f1=0.881]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.14758138772514132 iou=0.7924858897104767 f1=0.8807058205452745\n","Saving model with iou 0.7924858897104767\n","\n","Epoch: 13\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:20<00:00,  4.14s/it, iou=0.813, loss=0.137, f1=0.89]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.2381e-04.\n","    Phase: train -->  loss=0.1370964558685527 iou=0.8128595596990545 f1=0.889902778923419\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:33<00:00,  3.71s/it, iou=0.774, loss=0.164, f1=0.866]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.16420285238160026 iou=0.7735971214322873 f1=0.8664027121117366\n","Not saving for iou 0.7735971214322873\n","\n","Epoch: 14\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:22<00:00,  4.20s/it, iou=0.823, loss=0.126, f1=0.898]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.2757e-04.\n","    Phase: train -->  loss=0.12568319084889748 iou=0.8230921238770892 f1=0.8978120315578085\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.96s/it, iou=0.791, loss=0.143, f1=0.884]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.14292075236638388 iou=0.7911355041846905 f1=0.8837729820119099\n","Not saving for iou 0.7911355041846905\n","\n","Epoch: 15\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:26<00:00,  4.29s/it, iou=0.816, loss=0.129, f1=0.892]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.3160e-04.\n","    Phase: train -->  loss=0.1287920582382118 iou=0.8161604985796771 f1=0.8920684429316191\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.95s/it, iou=0.786, loss=0.153, f1=0.874]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.15310684757100212 iou=0.7861409577570946 f1=0.8740907434738211\n","Not saving for iou 0.7861409577570946\n","\n","Epoch: 16\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:25<00:00,  4.29s/it, iou=0.829, loss=0.119, f1=0.901]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.3590e-04.\n","    Phase: train -->  loss=0.11946897219647379 iou=0.8294388645639562 f1=0.9007859628332234\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.94s/it, iou=0.781, loss=0.164, f1=0.872]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.16436170703834957 iou=0.7811270915179536 f1=0.8723609425961034\n","Not saving for iou 0.7811270915179536\n","\n","Epoch: 17\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:23<00:00,  4.23s/it, iou=0.811, loss=0.127, f1=0.892]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.4045e-04.\n","    Phase: train -->  loss=0.1267304435810622 iou=0.8112887028674882 f1=0.8922704799432642\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.99s/it, iou=0.776, loss=0.158, f1=0.863]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.15777406179242665 iou=0.7755811241497198 f1=0.8631735208721985\n","Not saving for iou 0.7755811241497198\n","\n","Epoch: 18\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:25<00:00,  4.29s/it, iou=0.831, loss=0.114, f1=0.903]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.4527e-04.\n","    Phase: train -->  loss=0.11390459449852214 iou=0.8314686188105529 f1=0.9033269844247407\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:34<00:00,  3.80s/it, iou=0.745, loss=0.186, f1=0.828]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.18612199359469944 iou=0.7449569383063701 f1=0.8281131925419066\n","Not saving for iou 0.7449569383063701\n","\n","Epoch: 19\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:24<00:00,  4.25s/it, iou=0.818, loss=0.121, f1=0.894]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.5034e-04.\n","    Phase: train -->  loss=0.1210959882420652 iou=0.8181550022451244 f1=0.8937858659466216\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.94s/it, iou=0.712, loss=0.192, f1=0.823]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.19182920787069532 iou=0.7124825297105819 f1=0.823416163114571\n","Not saving for iou 0.7124825297105819\n","\n","Epoch: 20\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:24<00:00,  4.26s/it, iou=0.825, loss=0.119, f1=0.897]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.5566e-04.\n","    Phase: train -->  loss=0.1192224994301796 iou=0.8254461489675061 f1=0.8973835730223556\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.99s/it, iou=0.788, loss=0.144, f1=0.877]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.14419694575998518 iou=0.787973302961879 f1=0.8774516904206714\n","Not saving for iou 0.787973302961879\n","\n","Epoch: 21\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:23<00:00,  4.23s/it, iou=0.839, loss=0.106, f1=0.908]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.6123e-04.\n","    Phase: train -->  loss=0.10649386475629666 iou=0.839145335180262 f1=0.9083283955651019\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.93s/it, iou=0.796, loss=0.136, f1=0.884]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.1362819323937098 iou=0.7959544826092098 f1=0.8841616832299128\n","Saving model with iou 0.7959544826092098\n","\n","Epoch: 22\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:23<00:00,  4.23s/it, iou=0.847, loss=0.103, f1=0.91]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.6705e-04.\n","    Phase: train -->  loss=0.10266267968451276 iou=0.8474080733212107 f1=0.9102651322035352\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.91s/it, iou=0.799, loss=0.134, f1=0.891]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.13441799415482414 iou=0.7989555293888178 f1=0.8908546082138269\n","Saving model with iou 0.7989555293888178\n","\n","Epoch: 23\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:21<00:00,  4.17s/it, iou=0.844, loss=0.107, f1=0.905]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.7311e-04.\n","    Phase: train -->  loss=0.10676440070657169 iou=0.8439147664154795 f1=0.9054773112472989\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:33<00:00,  3.76s/it, iou=0.784, loss=0.174, f1=0.847]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.1737411411272155 iou=0.7843725080317265 f1=0.8465147576055633\n","Not saving for iou 0.7843725080317265\n","\n","Epoch: 24\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:25<00:00,  4.27s/it, iou=0.83, loss=0.114, f1=0.898]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.7941e-04.\n","    Phase: train -->  loss=0.11430932953953743 iou=0.8298773034807607 f1=0.8977280046519744\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.90s/it, iou=0.784, loss=0.157, f1=0.862]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.15727762546804216 iou=0.7836181928589362 f1=0.8622174468173482\n","Not saving for iou 0.7836181928589362\n","\n","Epoch: 25\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:24<00:00,  4.24s/it, iou=0.81, loss=0.125, f1=0.889]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.8594e-04.\n","    Phase: train -->  loss=0.12477139909477795 iou=0.8104746146571508 f1=0.8892841195764402\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:34<00:00,  3.81s/it, iou=0.758, loss=0.156, f1=0.868]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.15619421750307083 iou=0.7575323122667091 f1=0.8676141327104478\n","Not saving for iou 0.7575323122667091\n","\n","Epoch: 26\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:24<00:00,  4.25s/it, iou=0.815, loss=0.118, f1=0.892]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.9270e-04.\n","    Phase: train -->  loss=0.11813901255235952 iou=0.8146697620612393 f1=0.8919485746355204\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:36<00:00,  4.02s/it, iou=0.741, loss=0.178, f1=0.849]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.17805038723680708 iou=0.7408811995278973 f1=0.8494059022587068\n","Not saving for iou 0.7408811995278973\n","\n","Epoch: 27\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:25<00:00,  4.28s/it, iou=0.793, loss=0.139, f1=0.874]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.9969e-04.\n","    Phase: train -->  loss=0.1391486429116305 iou=0.7926754871056793 f1=0.8740808553038472\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.92s/it, iou=0.761, loss=0.149, f1=0.863]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.14926664531230927 iou=0.7609036385032404 f1=0.8632713551207348\n","Not saving for iou 0.7609036385032404\n","\n","Epoch: 28\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:25<00:00,  4.27s/it, iou=0.821, loss=0.115, f1=0.897]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 2.0690e-04.\n","    Phase: train -->  loss=0.11500518593718023 iou=0.8213815663116312 f1=0.8968919564008796\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:34<00:00,  3.80s/it, iou=0.758, loss=0.188, f1=0.844]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.18789136161406836 iou=0.7581625157771421 f1=0.8435560583140271\n","Not saving for iou 0.7581625157771421\n","\n","Epoch: 29\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:24<00:00,  4.26s/it, iou=0.818, loss=0.118, f1=0.895]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 2.1433e-04.\n","    Phase: train -->  loss=0.117621189531158 iou=0.818354786469654 f1=0.8948930244371057\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.98s/it, iou=0.781, loss=0.14, f1=0.878]\n"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.1399662411875195 iou=0.7805940836030402 f1=0.8777199873862127\n","Not saving for iou 0.7805940836030402\n","\n","Epoch: 30\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [02:26<00:00,  4.30s/it, iou=0.818, loss=0.117, f1=0.896]\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 2.2196e-04.\n","    Phase: train -->  loss=0.11683815191773807 iou=0.8180899070598731 f1=0.8961679688067773\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:35<00:00,  3.97s/it, iou=0.778, loss=0.168, f1=0.847]"]},{"output_type":"stream","name":"stdout","text":["    Phase: val -->  loss=0.16827560795678032 iou=0.7776023095196631 f1=0.8473229725558498\n","Not saving for iou 0.7776023095196631\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["best_iou = 0\n","\n","for epoch in range(1, params['epochs']+1):\n","    print(f'\\nEpoch: {epoch}')\n","    for phase in ['train', 'val']:\n","        total_intersection=0\n","        total_union=0\n","        total_loss=0\n","        total_f1=0\n","\n","        pbar = tqdm(enumerate(dataloaders_dict[phase]),\n","                              total=len(dataloaders_dict[phase]),\n","                              leave=True,\n","                              dynamic_ncols=True)\n","        for i, (img, mask) in pbar:\n","            img, mask = img.to(params['device'], non_blocking=True), mask.to(params['device'], non_blocking=True)\n","\n","            # training\n","            if phase == 'train':\n","                loss, intersection, union, f1 = train(model, img, mask)\n","            # validation\n","            else:\n","                loss, intersection, union, f1 = val(model, img, mask)\n","\n","            # free GPU\n","            del img\n","            del mask\n","\n","            total_intersection += intersection\n","            total_union += union\n","            total_loss += loss\n","            iou = total_intersection/total_union\n","            total_f1 += f1\n","            pbar.set_postfix({'iou': iou, 'loss': total_loss/(i+1), 'f1': total_f1/(i+1)})\n","\n","        total_loss /= len(dataloaders_dict[phase])\n","        total_f1 /= len(dataloaders_dict[phase])\n","\n","        if phase == 'train':\n","          scheduler.step()\n","\n","        print(f'    Phase: {phase} -->  loss={total_loss} iou={iou} f1={total_f1}')\n","\n","    # save best model\n","    if iou > best_iou:\n","      print(f'Saving model with iou {iou}')\n","      save_model(epoch, model, ckpt_path=PATH_SRC, val_iou=iou)\n","      best_iou = iou\n","    else:\n","      print(f'Not saving for iou {iou}')\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100","collapsed_sections":["aZOSd9GK8hmW","lTvGbjxRmWnR"],"toc_visible":true,"authorship_tag":"ABX9TyPIyvKGNvKbbM3FEOtAuk8R"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"bdf3be2c2ae74e4db188c73a4e7c0c8e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd2069e0c45a4fb2b576dbe1135cc7d9","IPY_MODEL_209ad6e0f28f4c838b9daa81a25d7a1e","IPY_MODEL_2cb11161d9e540908fd5e8b45fc4b368"],"layout":"IPY_MODEL_9c78be33c0764fbfbc8d88d7fa755746"}},"dd2069e0c45a4fb2b576dbe1135cc7d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2029facba8b746c297dc47c5f145de92","placeholder":"​","style":"IPY_MODEL_ddbba79759c5449da83e73f5cb14e021","value":"Downloading (…)lve/main/config.json: 100%"}},"209ad6e0f28f4c838b9daa81a25d7a1e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbaf1dacadd94e47b181988d58f55ebd","max":6885,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3555715350994afcbd96f3e7042a742c","value":6885}},"2cb11161d9e540908fd5e8b45fc4b368":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9134b8ec80e24447a938f81affd5d7e0","placeholder":"​","style":"IPY_MODEL_c256bf3250dd49c2bb798cb35889b739","value":" 6.88k/6.88k [00:00&lt;00:00, 579kB/s]"}},"9c78be33c0764fbfbc8d88d7fa755746":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2029facba8b746c297dc47c5f145de92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddbba79759c5449da83e73f5cb14e021":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbaf1dacadd94e47b181988d58f55ebd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3555715350994afcbd96f3e7042a742c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9134b8ec80e24447a938f81affd5d7e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c256bf3250dd49c2bb798cb35889b739":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32020a57b7d54da9a9dc9e91a6d9c989":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b3281f7b09f54fa381297d832955ff40","IPY_MODEL_bc3c489fb0854cc3a34723be9831ed3c","IPY_MODEL_7baba65c94244f0189c44122c468ddfc"],"layout":"IPY_MODEL_5d992fa6502044bdb192cabf3ae87b29"}},"b3281f7b09f54fa381297d832955ff40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a11be9f2935a412f81b8b3706e3ba2b0","placeholder":"​","style":"IPY_MODEL_a428bd8a53124a6db5e4ce694d4a6334","value":"Downloading pytorch_model.bin: 100%"}},"bc3c489fb0854cc3a34723be9831ed3c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8686c6a966774035a7ebd46992e7b699","max":54944801,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df3eba0ab6b543c5beb52b6ba28dfac1","value":54944801}},"7baba65c94244f0189c44122c468ddfc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa8cb31b9d8a49a6875ca3796f6d5a29","placeholder":"​","style":"IPY_MODEL_5aa9bc0bc040459ea7f6d8c9173185b3","value":" 54.9M/54.9M [00:17&lt;00:00, 5.16MB/s]"}},"5d992fa6502044bdb192cabf3ae87b29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a11be9f2935a412f81b8b3706e3ba2b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a428bd8a53124a6db5e4ce694d4a6334":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8686c6a966774035a7ebd46992e7b699":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df3eba0ab6b543c5beb52b6ba28dfac1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa8cb31b9d8a49a6875ca3796f6d5a29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5aa9bc0bc040459ea7f6d8c9173185b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}